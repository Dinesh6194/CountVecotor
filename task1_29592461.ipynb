{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>FIT5196- Assignment 1: Parsing Data and Text Preprocessing.</center>\n",
    "## <center>Task 1: Parsing Data</center>\n",
    "### Student ID: 29592461\n",
    "### Student Name: Dinesh Karthikeyan\n",
    "#### Language: Python 3.7.0\n",
    "#### Working Environment: Jupyter Notebook\n",
    "#### Packages Used: re,  json\n",
    "#### Regex Checker: Pythex.\n",
    "#### Overview of  methodology: \n",
    "* The data set to be parsed is Unit guide (in html format) for several units, which is to be parsed and converted to xml and json in the format specified in the specification.\n",
    "* The required fields Unit Code, Title, Prerequistite, Synopsis, Requirement, Prohibitions, Outcomes and Chief examiner for each unit are to be fetched and stored in xml and json file with the format specified.\n",
    "* First step is to read the contents from the file \"*29592461.txt*\".\n",
    "* Then using Regular expression take details of every unut separately and store it in a list.\n",
    "* Proceed further and fetch all other required fields using regular expression by iterating through this list and writing the values into the xml and json files based on the format specified by the specification and add appropriate values if a unit doesn't have the required field or the value for the required field. (i.e.) For Prerequisite, Prohibitions, Requirement, Outcomes the value to be used is \"**NA**\" and for Chief Examiner it is \"**TBA**\".\n",
    "* After parsing the required data, store the values in the specified format into \"*29592461.xml*\" for xml and \"*29592461.json*\" for json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* re - used for Regular expression functionalities.\n",
    "* json - used for writing to Json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Variable Intialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialising variables for all the regular expressions (regex) to be used and string varialbles for json and xml strings that are to be written in the file as output.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open('29592461.txt')\n",
    "file_content=file.read()\n",
    "json_dict={'units':{'unit':[]}}\n",
    "i=-1\n",
    "xml_op='<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\\n<units>\\n'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching each unit and to put into list the regex (Units): `((?<=<div class=\"hbk-banner-box\">)([\\w\\W\\s]*?)(?=</nav>|<!-- /.content_container--> </div>))` is used.\n",
    "* The approach to get this regex : \n",
    "    * To fectch the contents between `<div class=\"hbk-banner-box\">` and `</nav>` or `<!-- /.content_container--> </div>` tags, so these form the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "    * The second group is `[\\w\\W\\s]*` fetch all the words,symbols and spaces, this will bring entire file so used `?` for this group to get values in non greedy manner and all three sub groups are put into a major group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "units_pattern=r'((?<=<div class=\"hbk-banner-box\">)([\\w\\W\\s]*?)(?=</nav>|<!-- /.content_container--> </div>))'      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Unit code from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<span class=\"unitcode\">)(\\w{3,4}\\d{4})(?=</span>))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<span class=\"unitcode\">` and `</span>` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `\\w{3,4}\\d{4}` fetch a string having 3 or 4 alphabet and 4 digits (e.g. FIT5196, ABCD1000). \n",
    "        * All three groups into a major group so as to get only the matched unitcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_code_pattern = r'((?<=<span class=\"unitcode\">)(\\w{3,4}\\d{4})(?=</span>))'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Synopsis from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<h2 class=\"hbk-heading\">Synopsis</h2>\\s<div>\\s<p>)(.*)(?=</p>\\s))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<h2 class=\"hbk-heading\">Synopsis</h2>\\s<div>\\s<p>` and `</p>\\s` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `.*` fetch all the data. \n",
    "        * All three groups into a major group so as to get the synopsis (only within the first p tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_synopsis_pattern=r'((?<=<h2 class=\"hbk-heading\">Synopsis</h2>\\s<div>\\s<p>)(.*)(?=</p>\\s))'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Prerequisite and Corequisite from the unit details (fetched with above regex (Units) and put into list) the regex: `(((?:<p class=\"hbk-preamble-heading\">Prerequisites</p>\\s)(.*)(?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))?)|((?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))(?:</span>|</p>)))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch contents starting with `<p class=\"hbk-preamble-heading\">Prerequisites</p>\\s)` or` \\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s` and ends with `</span>|</p>`. But in few cases either prequisite and corequisite both are present or only one of them is present so `(<p class=\"hbk-preamble-heading\">Prerequisites</p>\\s)(.*)(?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))?` this to get prerequiste and corequisite if both are present or only prerequisite alone if no corequiste, `(<p class=\"hbk-preamble-heading\">Prerequisites</p>\\s)(.*)(?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))?)|((\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))` this is used to fetch even prerequisite and corequiste even if the other is missng.\n",
    "        * `?:` is added to make the groups non capturing so as to get only the values between them.\n",
    "        * Finally all the groups are put into a major group to fetch only the values required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_Prerequisite_pattern=r'(((?:<p class=\"hbk-preamble-heading\">Prerequisites</p>\\s)(.*)(?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))?)|((?:\\s<p class=\"hbk-preamble-heading\">Co-requisites</p>\\s(.*))(?:</span>|</p>)))'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Requirement from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<h2 class=\"hbk-heading\">Assessment</h2>\\s<div>)([\\w\\W\\s]*?)(?=</div>))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<h2 class=\"hbk-heading\">Assessment</h2>\\s<div>` and `</div>` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `[\\w\\W\\s]*` fetch all the words, symbols and spaces,this will bring entire file so used `?` for this group to get values in non greedy manner and all three sub groups are put into a major group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_requirement_pattern=r'((?<=<h2 class=\"hbk-heading\">Assessment</h2>\\s<div>)([\\w\\W\\s]*?)(?=</div>))'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Prohibitions from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<p class=\"hbk-preamble-heading\">Prohibitions</p>\\s<p>)([\\w\\W\\s]*?)(?=</p>\\s</div>))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<p class=\"hbk-preamble-heading\">Prohibitions</p>\\s<p>` and `</p>\\s</div>` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `[\\w\\W\\s]*` fetch all the words, symbols and spaces,this will bring entire file so used `?` for this group to get values in non greedy manner and all three sub groups are put into a major group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_prohibition_pattern=r'((?<=<p class=\"hbk-preamble-heading\">Prohibitions</p>\\s<p>)([\\w\\W\\s]*?)(?=</p>\\s</div>))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Unit Title from the unit details (fetched with above regex (Units) and put into list) the regex: `(?<=</span>\\s-\\s)(.*)(?=<span)` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `</span>\\s-\\s` and `<span` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `.*` fetch all the data. \n",
    "        * All three groups into a major group so as to get the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_title_pattern=r'(?<=</span>\\s-\\s)(.*)(?=<span)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Outcomes from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<h2 class=\"hbk-heading\">Outcomes</h2>\\s)([\\w\\W\\s]*?)(?=((</ol>\\s</div>|</ul>\\s</div>))))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<h2 class=\"hbk-heading\">Outcomes</h2>\\s` and `((</ol>\\s</div>|</ul>\\s</div>)))` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `[\\w\\W\\s]*` fetch all the words, symbols and spaces,this will bring entire file so used `?` for this group to get values in non greedy manner and all three sub groups are put into a major group.\n",
    "        * This gives all the Vslues under the Outcome tag.\n",
    "        * From that `(?:<li>)([\\W\\w]*?)(?:</li>\\s)` this is used to get only the outcome values that are under the lis tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_outcome_pattern=r'((?<=<h2 class=\"hbk-heading\">Outcomes</h2>\\s)([\\w\\W\\s]*?)(?=((</ol>\\s</div>|</ul>\\s</div>))))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_outcome_list_pattern=r'(?:<li>)([\\W\\w]*?)(?:</li>\\s)'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For fetching Chief-Examiner from the unit details (fetched with above regex (Units) and put into list) the regex: `((?<=<p class=\"hbk-highlight-heading\">Chief examiner\\(s\\)</p>\\s<p>\\s)([\\w\\W\\s]*?)(?=</p>))` is used.\n",
    "    * The approach to get this regex:\n",
    "        * To fetch the contents between `<p class=\"hbk-highlight-heading\">Chief examiner\\(s\\)</p>\\s<p>\\s` and `</p>` tags, so these for the first and third group, to specify starts with `?<=` is added and to specify ends with `?=` is used.\n",
    "        * The second group is `[\\w\\W\\s]*` fetch all the words, symbols and spaces,this will bring entire file so used `?` for this group to get values in non greedy manner and all three sub groups are put into a major group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_chief_examiner_pattern=r'((?<=<p class=\"hbk-highlight-heading\">Chief examiner\\(s\\)</p>\\s<p>\\s)([\\w\\W\\s]*?)(?=</p>))'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing Phase:\n",
    "\n",
    "* Fetching the Unit details and putting into the list (units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "units=re.findall(units_pattern,file_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iterating through the list to parse for each unit. (Inline comments gives the description )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit_val in units: # Traversing through each unit.\n",
    "    unit_code=''\n",
    "    unit_title=''\n",
    "    unit_prerequisite=[]\n",
    "    unit_synopsis=''\n",
    "    unit_requirements=[]\n",
    "    unit_prohibitions_list=[]\n",
    "    unit_outcome=[]\n",
    "    unit_chief_examiner=[]\n",
    "    unit=unit_val[1]    \n",
    "    # Fetching Unit title.\n",
    "    unit_title=re.findall(unit_title_pattern,unit) \n",
    "    i+=1\n",
    "    # Fetching Unit code.\n",
    "    unit_code=re.findall(unit_code_pattern,unit)[0][1] if len(re.findall(unit_code_pattern,unit))>0 else 'NA' \n",
    "    unit_prerequisite_data=re.findall(unit_Prerequisite_pattern,unit) # Fetching the Prerequisite contents.\n",
    "    if len(unit_prerequisite_data)>0:\n",
    "        for unit_prerequisite_data_val in unit_prerequisite_data: \n",
    "            unit_prerequisite_val=unit_prerequisite_data_val[0]\n",
    "            # Parsing through the Prerequisite contents to get only the unit codes of prerequisite.\n",
    "            unit_prerequisite=list(set(re.findall(r'\\w{3,4}\\d{4}',unit_prerequisite_val)))\n",
    "            \n",
    "            if len(unit_prerequisite) ==0 :\n",
    "                unit_prerequisite.append('NA')  # Adding NA for empty prerequisite.      \n",
    "    else:\n",
    "        unit_prerequisite.append('NA')  # Adding NA if there no Prerequisite tag.\n",
    " \n",
    "    # Fetching Synopsis Contents.\n",
    "    unit_synopsis_temp=re.findall(unit_synopsis_pattern,unit)[0][1] if len(re.findall(unit_synopsis_pattern,unit))>0 else 'NA'\n",
    "    # Removing Unnecessary tags.\n",
    "    unit_synopsistemp1=re.sub(r'((?:<span)(?:.*?)(?:html\">))','',unit_synopsis_temp)\n",
    "    unit_synopsistemp2=re.sub(r'(</a.</span>)','',unit_synopsistemp1)\n",
    "    unit_synopsis=unit_synopsistemp2\n",
    "    # Fetching Requirement Contents.\n",
    "    unit_requirement=re.findall(unit_requirement_pattern,unit)\n",
    "    if len(unit_requirement)>0:\n",
    "        for unit_requirement_data in unit_requirement:   # Iterating throught to get the required conetnt. \n",
    "            # Fecthing the values from p tags.\n",
    "            unit_requirement_val_list=re.findall(r'(((?<=<p>)([\\w\\W\\s]*?)(?=</p>)))',unit_requirement_data[1])            \n",
    "            if len(unit_requirement_val_list)==0:\n",
    "                unit_requirements.append('NA') # Adding NA if no matches.\n",
    "            else:    \n",
    "                for unit_requirement_val in unit_requirement_val_list: # Iterate Matches  and remove unnecessary tags.\n",
    "                        temp= re.sub(r'((?:<a)(?:[\\w\\W\\s]*?)(?:.html\">))', '', unit_requirement_val[1])\n",
    "                         \n",
    "                        temp1=re.sub(r'((?:</a><span)(?:.*)(?:\">))|((?:<span)(?:.*)(?:\">))','',temp)\n",
    "                        \n",
    "                        \n",
    "                        temp2=re.sub(r'(</a>|</span>)','',temp1)\n",
    "                        unit_requirements.append(temp2)\n",
    "                        #unit_requirements.append(unit_requirement_val[1])\n",
    "                        \n",
    "    else:\n",
    "        unit_requirements.append('NA') # Add NA if no Tag found.\n",
    "            \n",
    "    \n",
    "    unit_prohibitions_data=re.findall(unit_prohibition_pattern,unit) # Fetching Prohibitions content.\n",
    "    \n",
    "    \n",
    "    if len(unit_prohibitions_data)==0:\n",
    "        unit_prohibitions_list.append('NA') # Adding NA if no matches.\n",
    "    else:\n",
    "        for unit_prohibition in unit_prohibitions_data: # Iterate through matches and fetch only unit codes.\n",
    "            unit_prohibitions_list_temp=(re.findall(r'\\w{3,4}\\d{4}',unit_prohibition[1]))\n",
    "            # Add NA if no unit code is found  else Add the unique values of unit code.\n",
    "            unit_prohibitions_list= list(set(unit_prohibitions_list+ unit_prohibitions_list_temp if len(unit_prohibitions_list_temp)>0 else ['NA']))\n",
    "    \n",
    "    unit_outcomes=re.findall(unit_outcome_pattern,unit) # Fetching Outcome Contents.\n",
    "    if len(unit_outcomes)>0:\n",
    "        for unit_outcome_val in unit_outcomes: # Iterate through the matches to fetch the list (html li tag) values.\n",
    "            temp= re.findall(unit_outcome_list_pattern,unit_outcome_val[1]) # Fetching values in the list (html li tag)\n",
    "            for each in temp:\n",
    "                # Removing Unnecessary tags.\n",
    "                temp1=re.sub('((<span)(.*?)(html\">))|((<ol)(.*?)(\">))','',each)\n",
    "                temp2=re.sub(r'(</a></span>)','',temp1)\n",
    "                temp3=re.sub(r'(<p>|</p>|<ul>|<li>)','',temp2)\n",
    "                unit_outcome.append(temp3)\n",
    "            \n",
    "    else:\n",
    "        unit_outcome.append(\"NA\") # Adding NA if No tag.\n",
    "    # Fetching Chief examiner contents.\n",
    "    unit_chief_examiner_data=re.findall(unit_chief_examiner_pattern,unit) if len(re.findall(unit_chief_examiner_pattern,unit))>0 else ['TBA']\n",
    "    # If the Value is not TBA  directly check for the inner content and if its TBA add TBA \n",
    "    # else add the values matching a pattern.\n",
    "    if unit_chief_examiner_data[0]!='TBA':\n",
    "        if \"TBA\" in str(unit_chief_examiner_data[0]):\n",
    "            unit_chief_examiner.append(\"TBA\")\n",
    "            \n",
    "        else:\n",
    "            unit_chief_examiner=re.findall(r'(?:(?:<a.*\">)([\\w\\W\\s]*?)(?:</a>))|((?:A/)(.*))',unit_chief_examiner_data[0][1])\n",
    "    else:\n",
    "        unit_chief_examiner.append(\"TBA\") # Add TBA if it has TBA.\n",
    "    \n",
    "    # Xml string and Json dictionary formation for writing into file.\n",
    "    xml_op+=\"<unit id='{0}'>\\n\\n\\n<title>{1}</title>\\n<synopsis>{2}</synopsis>\\n<pre_requistics>\".format(unit_code,unit_title[0],unit_synopsis)\n",
    "    \n",
    "    json_dict['units']['unit'].append({'@id':unit_code,'title':unit_title[0],'synopsis':unit_synopsis})\n",
    "    if unit_prerequisite[0]!=\"NA\":\n",
    "        if len(unit_prerequisite)>1:\n",
    "            json_dict['units']['unit'][i]['pre_requistics']={'pre_requistic':[]}\n",
    "        elif len(unit_prerequisite)==1:\n",
    "            json_dict['units']['unit'][i]['pre_requistics']={'pre_requistic':''}\n",
    "        xml_op+=\"\\n\"\n",
    "    for each in unit_prerequisite:\n",
    "        if each!=\"NA\":\n",
    "            xml_op+=\"<pre_requistic>{0}</pre_requistic>\".format(each)\n",
    "            if len(unit_prerequisite)>1:\n",
    "                json_dict['units']['unit'][i]['pre_requistics']['pre_requistic'].append(each)\n",
    "            elif len(unit_prerequisite)==1:\n",
    "                json_dict['units']['unit'][i]['pre_requistics']['pre_requistic']=each\n",
    "        else:\n",
    "            xml_op+=each\n",
    "            json_dict['units']['unit'][i]['pre_requistics']=each\n",
    "                \n",
    "    xml_op+=\"</pre_requistics>\\n<prohibisions>\"\n",
    "    count=0\n",
    "    for each in unit_prohibitions_list:\n",
    "        count+=1\n",
    "        if each==\"NA\":\n",
    "            xml_op+=\"{0}</prohibisions>\\n\".format(each)\n",
    "            json_dict['units']['unit'][i]['prohibisions']=each\n",
    "        else:\n",
    "            if count==1:\n",
    "                xml_op+=\"\\n\"\n",
    "                if len(unit_prohibitions_list)>1:\n",
    "                    json_dict['units']['unit'][i]['prohibisions']={'prohibision':[]}\n",
    "                    \n",
    "                elif len(unit_prohibitions_list)==1:\n",
    "                    json_dict['units']['unit'][i]['prohibisions']={'prohibision':''}\n",
    "            if len(unit_prohibitions_list)>1:\n",
    "                json_dict['units']['unit'][i]['prohibisions']['prohibision'].append(each)\n",
    "            elif len(unit_prohibitions_list)==1:\n",
    "                json_dict['units']['unit'][i]['prohibisions']['prohibision']=each\n",
    "            xml_op+=\"<prohibision>{0}</prohibision>\".format(each)\n",
    "            \n",
    "            if count==len(unit_prohibitions_list):\n",
    "                xml_op+=\"</prohibisions>\\n\"\n",
    "    xml_op+=\"<requirements>\"\n",
    "    \n",
    "    new=0\n",
    "    for each in unit_requirements:\n",
    "        new+=1\n",
    "        if each==\"NA\":\n",
    "            xml_op+=\"NA\"\n",
    "            json_dict['units']['unit'][i]['requirements']=\"NA\"\n",
    "        else:\n",
    "            if new==1:\n",
    "                xml_op+=\"\\n\"\n",
    "                \n",
    "                if len(unit_requirements)>1:\n",
    "                    json_dict['units']['unit'][i]['requirements']={'requirement':[]}\n",
    "                    \n",
    "                elif len(unit_requirements)==1:\n",
    "                    json_dict['units']['unit'][i]['requirements']={'requirement':''}\n",
    "            if len(unit_requirements)>1:\n",
    "                json_dict['units']['unit'][i]['requirements']['requirement'].append(each)\n",
    "            elif len(unit_requirements)==1:\n",
    "                json_dict['units']['unit'][i]['requirements']['requirement']=each  \n",
    "            xml_op+=\"<requirement>{0}</requirement>\".format(each)\n",
    "              \n",
    "    xml_op+=\"</requirements>\\n<outcomes>\\n\"\n",
    "    new=0\n",
    "    for each in unit_outcome:\n",
    "        new+=1\n",
    "        # Using flag (new) for checing first value and index for units (i).\n",
    "        if new==1:\n",
    "            if len(unit_outcome)>1:\n",
    "                json_dict['units']['unit'][i]['outcomes']={'outcome':[]}\n",
    "                \n",
    "            elif len(unit_outcome)==1:\n",
    "                json_dict['units']['unit'][i]['outcomes']={'outcome':''}\n",
    "        if len(unit_outcome)>1:        \n",
    "            json_dict['units']['unit'][i]['outcomes']['outcome'].append(each)\n",
    "        elif len(unit_outcome)==1:\n",
    "            json_dict['units']['unit'][i]['outcomes']['outcome']=each\n",
    "            \n",
    "        xml_op+=\"<outcome>{0}</outcome>\".format(each)\n",
    "       \n",
    "    xml_op+=\"</outcomes>\\n<chief_examiners>\"\n",
    "   \n",
    "    if unit_chief_examiner[0]!=\"TBA\":\n",
    "        xml_op+=\"\\n\"\n",
    "        if len(unit_chief_examiner)>1:\n",
    "            json_dict['units']['unit'][i]['chief_examiners']={'chief_examiner':[]}\n",
    "        elif len(unit_chief_examiner)==1:\n",
    "            json_dict['units']['unit'][i]['chief_examiners']={'chief_examiner':''}\n",
    "        for each in unit_chief_examiner:\n",
    "            if each[0]!=\"TBA\" and each[0] is not None:\n",
    "                xml_op+=\"<chief_examiner>{0}</chief_examiner>\".format(each[0])\n",
    "                if len(unit_chief_examiner)==1:\n",
    "                    json_dict['units']['unit'][i]['chief_examiners']['chief_examiner']=each[0]\n",
    "                elif len(unit_chief_examiner)>1:\n",
    "                    json_dict['units']['unit'][i]['chief_examiners']['chief_examiner'].append(each[0])\n",
    "            elif each[1]!=\"TBA\" and each[1] is not None:\n",
    "                xml_op+=\"<chief_examiner>{0}</chief_examiner>\".format(each[1])\n",
    "                if len(unit_chief_examiner)==1:\n",
    "                    json_dict['units']['unit'][i]['chief_examiners']['chief_examiner']=each[1]\n",
    "                elif len(unit_chief_examiner)>1:\n",
    "                    json_dict['units']['unit'][i]['chief_examiners']['chief_examiner'].append(each[1])\n",
    "    else:\n",
    "        xml_op+=\"TBA\"\n",
    "        json_dict['units']['unit'][i]['chief_examiners']=\"TBA\"\n",
    "            \n",
    "    xml_op+=\"</chief_examiners>\\n</unit>\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing output:\n",
    "* Xml string is constructed with all the values from the parsing phase and with the necessary fromating.\n",
    "* Json dictionary is formed with the values from the parsing phase and with the dumps() function dumped into a string.\n",
    "* Both strings are written in separate files *2959246951.xml* and *29592461.json* respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the XMl String with the required formats into 29592461.xml.\n",
    "xml_op+=\"</units>\\n\" \n",
    "xml_op=xml_op.replace(\"&amp\",\"&#38\")\n",
    "output=open(\"29592461.xml\",'w')\n",
    "output.write(xml_op)\n",
    "output.close()\n",
    "# Dumping json dictionary into json string and writing into 29592461.json file.\n",
    "json_string=json.dumps(json_dict,indent=4)\n",
    "json_output=open(\"29592461.json\",\"w\")\n",
    "# Replacing the values according to unicode.\n",
    "json_string=json_string.replace(\"&amp;\",\"&\") \n",
    "json_string=json_string.replace(\"&gt;\",\">\")\n",
    "json_output.write(json_string)\n",
    "json_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
